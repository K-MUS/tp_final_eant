library("ROCR")
View(test)
predict = predict(model, newdata = test, type = "prob")[,2]
prediction = prediction(predict, Test$n.use)
library("ROCR")
View(test)
predict = predict(model, newdata = test, type = "prob")[,2]
prediction = prediction(predict, test$Attrition)
plot(performance(prediction, "tpr", "fpr"))
confusionMatrix(pred,test$Attrition)
conf_mat = predict(model, newdata = test, type = "class")
confusionMatrix(conf_mat,test$Attrition)
runApp('main.R')
library("ROCR")
install.packages("ROCR")
runApp('main.R')
runApp('main.R')
runApp('main.R')
runApp('main.R')
runApp('main.R')
runApp('main.R')
conf_mat_info
conf_mat = predict(model, newdata = test, type = "class")
conf_mat_info <- confusionMatrix(conf_mat,test$Attrition)
conf_mat_info
runApp('main.R')
sumary(conf_mat_info)
summary(conf_mat_info)
conf_mat = predict(model, newdata = test, type = "class")
conf_mat_info <- confusionMatrix(conf_mat,test$Attrition)
conf_mat_info
runApp('main.R')
runApp('main.R')
conf_mat = predict(model, newdata = test, type = "class")
runApp('main.R')
runApp('main.R')
runApp('main.R')
conf_mat = predict(model, newdata = test, type = "class")
conf_mat_info <- confusionMatrix(conf_mat,test$Attrition)
conf_mat_info
runApp('main.R')
runApp('main.R')
runApp('main.R')
install.packages("ROCR")
install("ROCR")
install.packages("ROCR")
library("ROCR")
install.packages("pROC")
library(ROCR)
library(pROC)
?pROC
# model <- rpart(Attrition ~ ., data=train)
model <- rpart(Attrition ~ ., data=train,control=rpart.control(minsplit=10,cp=0.001))
plot(model, uniform=TRUE, branch=0.6, margin=0.05,extra=0, type=2)
rpart.plot(model, extra=0, type=2)
library(rpart.plot)   #Decision Tree - Plots
rpart.plot(model, extra=0, type=2)
# model <- rpart(Attrition ~ ., data=train)
model <- rpart(Attrition ~ ., data=train,control=rpart.control(minsplit=20,cp=0.001))
plot(model, uniform=TRUE, branch=0.6, margin=0.05)
rpart.plot(model, extra=0, type=2)
library(ROCR)
pred <- predict(model, newdata = test[5,], type = "response")
plot(roc(test,test$Attrition), legacy.axes = TRUE)
predict = predict(model, newdata = test, type = "prob")[,2]
plot(roc(test,predict), legacy.axes = TRUE)
predict = predict(model, newdata = test, type = "prob")
View(predict)
predict = predict(model, newdata = test, type = "class")
plot(roc(test,predict), legacy.axes = TRUE)
plot(roc_(test,predict), legacy.axes = TRUE)
predict = predict(model, newdata = test, type = "prob")[,2]
predict = predict(model, newdata = test, type = "prob")
View(predict)
conf_mat = predict(model, newdata = test, type = "class")
View(tab_eda)
roc(conf_mat,predict,plot=TRUE)
roc(response = conf_mat, predictor = predict,plot=TRUE)
View(predict)
predict = predict(model, newdata = test, type = "prob")[,2]
roc(response = conf_mat, predictor = predict,plot=TRUE)
conf_mat_info <- confusionMatrix(conf_mat,test$Attrition)
conf_mat_info
predict = predict(model, newdata = test, type = "prob")[,1]
roc(response = conf_mat, predictor = predict,plot=TRUE)
roc(response = test$Attrition, predictor = predict,plot=TRUE)
roc(response = test$Attrition, predictor = predict,plot=TRUE, legacy.axes = TRUE)
par(pty="s")
roc(response = test$Attrition, predictor = predict,plot=TRUE, legacy.axes = TRUE, percent = TRUE, xlab= "False Positive Perc.", ylab= "True Positive Perc.")
roc(response = test$Attrition, predictor = predict,plot=TRUE, legacy.axes = TRUE, percent = TRUE, xlab= "False Positive Perc.", ylab= "True Positive Perc.",
color="#377EB8",lwd=4)
roc(response = test$Attrition, predictor = predict,plot=TRUE, legacy.axes = TRUE, percent = TRUE, xlab= "False Positive Perc.", ylab= "True Positive Perc.",
col="#377EB8",lwd=4)
roc(response = test$Attrition, predictor = predict,plot=TRUE, legacy.axes = TRUE, percent = TRUE, xlab= "False Positive Perc.", ylab= "True Positive Perc.",
col="#377EB8",lwd=4, print.auc=TRUE)
predict = predict(model, newdata = test, type = "prob")[,1]
par(pty="s")
roc(response = test$Attrition, predictor = predict,plot=TRUE, legacy.axes = TRUE, percent = TRUE, xlab= "False Positive Perc.", ylab= "True Positive Perc.",
col="#377EB8",lwd=4, print.auc=TRUE)
predict = predict(model, newdata = test, type = "prob")#[,1]
View(predict)
predict = predict(model, newdata = test, type = "prob")[,1]
par(pty="s")
roc(response = test$Attrition, predictor = predict,plot=TRUE, legacy.axes = TRUE, percent = TRUE, xlab= "False Positive Perc.", ylab= "True Positive Perc.",
col="#377EB8",lwd=4, print.auc=TRUE)
# model <- rpart(Attrition ~ ., data=train)
model <- rpart(Attrition ~ ., data=train,control=rpart.control(minsplit=10,cp=0.001))
pred <- predict(model, newdata = test[5,], type = "class")
conf_mat = predict(model, newdata = test, type = "class")
conf_mat_info <- confusionMatrix(conf_mat,test$Attrition)
conf_mat_info
predict = predict(model, newdata = test, type = "prob")[,1]
par(pty="s")
roc(response = test$Attrition, predictor = predict,plot=TRUE, legacy.axes = TRUE, percent = TRUE, xlab= "False Positive Perc.", ylab= "True Positive Perc.",
col="#377EB8",lwd=4, print.auc=TRUE)
# model <- rpart(Attrition ~ ., data=train)
model <- rpart(Attrition ~ ., data=train,control=rpart.control(minsplit=5,cp=0.001))
conf_mat = predict(model, newdata = test, type = "class")
conf_mat_info <- confusionMatrix(conf_mat,test$Attrition)
conf_mat_info
predict = predict(model, newdata = test, type = "prob")[,1]
par(pty="s")
roc(response = test$Attrition, predictor = predict,plot=TRUE, legacy.axes = TRUE, percent = TRUE, xlab= "False Positive Perc.", ylab= "True Positive Perc.",
col="#377EB8",lwd=4, print.auc=TRUE)
# model <- rpart(Attrition ~ ., data=train)
model <- rpart(Attrition ~ ., data=train,control=rpart.control(minsplit=10,cp=0.001))
conf_mat = predict(model, newdata = test, type = "class")
conf_mat_info <- confusionMatrix(conf_mat,test$Attrition)
conf_mat_info
predict = predict(model, newdata = test, type = "prob")[,1]
par(pty="s")
roc(response = test$Attrition, predictor = predict,plot=TRUE, legacy.axes = TRUE, percent = TRUE, xlab= "False Positive Perc.", ylab= "True Positive Perc.",
col="#377EB8",lwd=4, print.auc=TRUE)
# model <- rpart(Attrition ~ ., data=train)
model <- rpart(Attrition ~ ., data=train,control=rpart.control(minsplit=10))
conf_mat = predict(model, newdata = test, type = "class")
conf_mat_info <- confusionMatrix(conf_mat,test$Attrition)
conf_mat_info
predict = predict(model, newdata = test, type = "prob")[,1]
par(pty="s")
roc(response = test$Attrition, predictor = predict,plot=TRUE, legacy.axes = TRUE, percent = TRUE, xlab= "False Positive Perc.", ylab= "True Positive Perc.",
col="#377EB8",lwd=4, print.auc=TRUE)
model <- rpart(Attrition ~ ., data=train)
model
plot(model, uniform=TRUE, branch=0.6, margin=0.05)
text(model, all=TRUE, use.n=TRUE)
rpart.plot(model, extra=0, type=2)
conf_mat = predict(model, newdata = test, type = "class")
conf_mat_info <- confusionMatrix(conf_mat,test$Attrition)
conf_mat = predict(model, newdata = test, type = "class")
conf_mat_info <- confusionMatrix(conf_mat,test$Attrition)
library(caret)   #Split data
conf_mat_info <- confusionMatrix(conf_mat,test$Attrition)
conf_mat_info
predict = predict(model, newdata = test, type = "prob")[,1]
par(pty="s")
roc(response = test$Attrition, predictor = predict,plot=TRUE, legacy.axes = TRUE, percent = TRUE, xlab= "False Positive Perc.", ylab= "True Positive Perc.",
col="#377EB8",lwd=4, print.auc=TRUE)
#model <- rpart(Attrition ~ ., data=train)
model <- rpart(Attrition ~ ., data=train,control=rpart.control(minsplit=10,cp=0.001))
plot(model, uniform=TRUE, branch=0.6, margin=0.05)
text(model, all=TRUE, use.n=TRUE)
rpart.plot(model, extra=0, type=2)
conf_mat = predict(model, newdata = test, type = "class")
conf_mat_info <- confusionMatrix(conf_mat,test$Attrition)
conf_mat_info
predict = predict(model, newdata = test, type = "prob")[,1]
par(pty="s")
roc(response = test$Attrition, predictor = predict,plot=TRUE, legacy.axes = TRUE, percent = TRUE, xlab= "False Positive Perc.", ylab= "True Positive Perc.",
col="#377EB8",lwd=4, print.auc=TRUE)
# Complicated DecisionTree, Is there a way to determine variable importance?
var_imp <- data.frame(model$variable.importance)
var_imp$features <- rownames(var_imp)
var_imp <- var_imp[, c(2, 1)]
var_imp$importance <- round(var_imp$model.variable.importance, 2)
var_imp$model.variable.importance <- NULL
colorCount <- length(unique(var_imp$features))
feature_importance <- var_imp
ggplot(feature_importance, aes(x=reorder(features, importance), y=importance, fill=features)) +
geom_bar(stat='identity') +
coord_flip() +
geom_label(aes(label=paste0(importance, "%")), colour = "white", fontface = "italic", hjust=0.6) +
theme_minimal()
ggplot(feature_importance, aes(x=reorder(features, importance), y=importance, fill=features)) +
geom_bar(stat='identity') +
coord_flip() +
geom_label(aes(label=paste0(importance, "%")), colour = "white", fontface = "italic", hjust=0.6) +
# theme_minimal()
theme(legend.position="none", strip.background = element_blank(), strip.text.x = element_blank(),
plot.title=element_text(hjust=0.5, color="white"), plot.subtitle=element_text(color="white"), plot.background=element_rect(fill="#0D7680"),
axis.text.x=element_text(colour="white"), axis.text.y=element_text(colour="white"),
axis.title=element_text(colour="white"),
legend.background = element_rect(fill="#FFF9F5",
size=0.5, linetype="solid",
colour ="black"))
ggplot(feature_importance, aes(x=reorder(features, importance), y=importance, fill=features)) +
geom_bar(stat='identity') +
coord_flip() +
geom_label(aes(label=paste0(importance, "%")), colour = "white", fontface = "italic", hjust=0.6) +
theme_minimal()
ggplot(feature_importance, aes(x=reorder(features, importance), y=importance, fill=features)) +
geom_bar(stat='identity') +
coord_flip() +
geom_label(aes(label=paste0(importance, "%")), colour = "white", fontface = "italic", hjust=0.6) +
theme_minimal() +
theme(legend.position="none")
model <- rpart(Attrition ~ ., data=train)
# Complicated DecisionTree, Is there a way to determine variable importance?
var_imp <- data.frame(model$variable.importance)
var_imp$features <- rownames(var_imp)
var_imp <- var_imp[, c(2, 1)]
var_imp$importance <- round(var_imp$model.variable.importance, 2)
var_imp$model.variable.importance <- NULL
colorCount <- length(unique(var_imp$features))
feature_importance <- var_imp
ggplot(feature_importance, aes(x=reorder(features, importance), y=importance, fill=features)) +
geom_bar(stat='identity') +
coord_flip() +
geom_label(aes(label=paste0(importance, "%")), colour = "white", fontface = "italic", hjust=0.6) +
theme_minimal() +
theme(legend.position="none")
set.seed(666)
set.seed(123)
# Split data
trainIndex <- createDataPartition(df$Attrition, p=0.8,
list=FALSE, times=1)
train <- df[trainIndex,]
test <- df[-trainIndex,]
model <- rpart(Attrition ~ ., data=train)
plot(model, uniform=TRUE, branch=0.6, margin=0.05)
text(model, all=TRUE, use.n=TRUE)
conf_mat = predict(model, newdata = test, type = "class")
conf_mat_info <- confusionMatrix(conf_mat,test$Attrition)
conf_mat_info
predict = predict(model, newdata = test, type = "prob")[,1]
par(pty="s")
roc(response = test$Attrition, predictor = predict,plot=TRUE, legacy.axes = TRUE, percent = TRUE, xlab= "False Positive Perc.", ylab= "True Positive Perc.",
col="#377EB8",lwd=4, print.auc=TRUE)
set.seed(666)
# Split data
trainIndex <- createDataPartition(df$Attrition, p=0.8,
list=FALSE, times=1)
train <- df[trainIndex,]
test <- df[-trainIndex,]
model <- rpart(Attrition ~ ., data=train)
conf_mat = predict(model, newdata = test, type = "class")
conf_mat_info <- confusionMatrix(conf_mat,test$Attrition)
conf_mat_info
predict = predict(model, newdata = test, type = "prob")[,1]
par(pty="s")
roc(response = test$Attrition, predictor = predict,plot=TRUE, legacy.axes = TRUE, percent = TRUE, xlab= "False Positive Perc.", ylab= "True Positive Perc.",
col="#377EB8",lwd=4, print.auc=TRUE)
install.packages("randomForest")
#model randomForest
model <- randomForest(Attrition ~ .,data = train)
#model randomForest
model <- randomForest::randomForest(Attrition ~ .,data = train)
model
plot(model, uniform=TRUE, branch=0.6, margin=0.05)
text(model, all=TRUE, use.n=TRUE)
conf_mat = predict(model, newdata = test, type = "class")
conf_mat_info <- confusionMatrix(conf_mat,test$Attrition)
conf_mat_info
predict = predict(model, newdata = test, type = "prob")[,1]
par(pty="s")
roc(response = test$Attrition, predictor = predict,plot=TRUE, legacy.axes = TRUE, percent = TRUE, xlab= "False Positive Perc.", ylab= "True Positive Perc.",
col="#377EB8",lwd=4, print.auc=TRUE)
model <- randomForest::randomForest(Attrition ~ .,data = train,ntree=100, mtry=2)
model
#model randomForest
model <- randomForest::randomForest(Attrition ~ .,data = train)
model
model <- randomForest::randomForest(Attrition ~ .,data = train,ntree=100, mtry=2)
model
varImpPlot(model)
randomForest::varImpPlot(model)
install.packages("reprtree")
install.packages("party")
#party
model <- ctree(Attrition ~ .,data = train)
#party
model <- party::::ctree(Attrition ~ .,data = train)
#party
model <- party::ctree(Attrition ~ .,data = train)
plot(x, type="simple")
plot(model, type="simple")
model
#model randomForest
model <- randomForest::randomForest(Attrition ~ .,data = train)
model
#party
model <- party::ctree(Attrition ~ .,data = train)
plot(model, type="simple")
model
conf_mat = predict(model, newdata = test, type = "class")
conf_mat = predict(model, newdata = test, type = "response")
conf_mat_info <- confusionMatrix(conf_mat,test$Attrition)
conf_mat_info
#ROC
predict = predict(model, newdata = test, type = "prob")[,1]
par(pty="s")
#ROC
predict = predict(model, newdata = test, type = "prob")[,1]
#ROC
predict = predict(model, newdata = test, type = "prob")#[,1]
par(pty="s")
roc(response = test$Attrition, predictor = predict,plot=TRUE, legacy.axes = TRUE, percent = TRUE, xlab= "False Positive Perc.", ylab= "True Positive Perc.",
col="#377EB8",lwd=4, print.auc=TRUE)
#ROC
predict = predict(model, newdata = test, type = "prob")[,1]
par(pty="s")
roc(response = test$Attrition, predictor = predict,plot=TRUE, legacy.axes = TRUE, percent = TRUE, xlab= "False Positive Perc.", ylab= "True Positive Perc.",
col="#377EB8",lwd=4, print.auc=TRUE)
library(shiny); runApp('main.R')
original_df <- read.csv("Data/WA_Fn-UseC_-HR-Employee-Attrition.csv")
df <- original_df
colnames(df)[1] = "Age"
df$StandardHours<-NULL
df$PerformanceRating<-NULL
df$Over18<-NULL
df$EmployeeCount<-NULL
df$JobLevel<-NULL
df$DailyRate<-NULL
df$HourlyRate<-NULL
df$DailyRate<-NULL
df$MonthlyRate<-NULL
df$PercentSalaryHike<-NULL
df$EmployeeNumber<-NULL
df$MaritalStatus<-NULL
df$EducationField<-NULL
df$RelationshipSatisfaction<-NULL
df$WorkLifeBalance<-NULL
df$YearsSinceLastPromotion<-NULL
df$JobInvolvement<-NULL
# Split data
trainIndex <- createDataPartition(df$Attrition, p=0.8, list=FALSE, times=1)
set.seed(666)
# Split data
trainIndex <- createDataPartition(df$Attrition, p=0.8, list=FALSE, times=1)
train <- df[trainIndex,]
test <- df[-trainIndex,]
model <- rpart(Attrition ~ ., data=train,control=rpart.control(minsplit=10,cp=0.001))
conf_mat = predict(model, newdata = test, type = "class")
conf_mat_info <- confusionMatrix(conf_mat,test$Attrition)
conf_mat_info
#ROC
predict = predict(model, newdata = test, type = "prob")[,1]
par(pty="s")
roc(response = test$Attrition, predictor = predict,plot=TRUE, legacy.axes = TRUE, percent = TRUE, xlab= "False Positive Perc.", ylab= "True Positive Perc.",
col="#377EB8",lwd=4, print.auc=TRUE)
runApp('main.R')
#model randomForest
model_rf <- randomForest::randomForest(Attrition ~ .,data = train)
model_rf <- randomForest::randomForest(Attrition ~ .,data = train,ntree=100, mtry=2)
model_rf
randomForest::varImpPlot(model_rf)
model_rf
conf_mat = predict(model_tp, newdata = test, type = "response")
conf_mat_info <- confusionMatrix(conf_mat,test$Attrition)
conf_mat_info
#ROC
predict = predict(model_dt, newdata = test, type = "prob")[,1]
#ROC
predict = predict(model_dt, newdata = test, type = "prob")[,1]
model_dt <- rpart(Attrition ~ ., data=train)
model_dt <- rpart(Attrition ~ ., data=train,control=rpart.control(minsplit=10,cp=0.001))
model_dt
plot(model_dt, uniform=TRUE, branch=0.6, margin=0.05)
text(model_dt, all=TRUE, use.n=TRUE)
rpart.plot(model_dt, extra=0, type=2)
conf_mat = predict(model_dt, newdata = test, type = "class")
conf_mat_info <- confusionMatrix(conf_mat,test$Attrition)
conf_mat_info
#model randomForest
model_rf <- randomForest::randomForest(Attrition ~ .,data = train)
model_rf <- randomForest::randomForest(Attrition ~ .,data = train,ntree=100, mtry=2)
model_rf
randomForest::varImpPlot(model_rf)
model_rf
#party
model_tp <- party::ctree(Attrition ~ .,data = train)
plot(model_tp, type="simple")
model_tp
conf_mat = predict(model_tp, newdata = test, type = "response")
conf_mat_info <- confusionMatrix(conf_mat,test$Attrition)
conf_mat_info
#ROC
predict = predict(model_dt, newdata = test, type = "prob")[,1]
par(pty="s")
roc(response = test$Attrition, predictor = predict,plot=TRUE, legacy.axes = TRUE, percent = TRUE, xlab= "False Positive Perc.", ylab= "True Positive Perc.",
col="#377EB8",lwd=4, print.auc=TRUE)
runApp('main.R')
runApp()
runApp()
runApp('main.R')
runApp('main.R')
runApp('main.R')
runApp('main.R')
runApp()
runApp()
runApp('main.R')
runApp('main.R')
runApp('main.R')
runApp('main.R')
runApp('main.R')
runApp('main.R')
runApp('main.R')
runApp('main.R')
library(shiny); runApp('main.R')
runApp('main.R')
model_rf
#model randomForest
model_rf <- randomForest::randomForest(Attrition ~ .,data = train)
model_rf <- randomForest::randomForest(Attrition ~ .,data = train,ntree=100, mtry=2)
model_rf
#model randomForest
model_rf <- randomForest::randomForest(Attrition ~ .,data = train)
model_rf
model_rf
randomForest::varImpPlot(model_rf)
model_rf
runApp('main.R')
conf_mat_dt = predict(model_dt, newdata = test, type = "class")
conf_mat_info_dt <- confusionMatrix(conf_mat,test$Attrition)
conf_mat_info_dt
#model randomForest
model_rf <- randomForest::randomForest(Attrition ~ .,data = train)
model_rf <- randomForest::randomForest(Attrition ~ .,data = train,ntree=100, mtry=2)
model_rf
#party
model_tp <- party::ctree(Attrition ~ .,data = train)
plot(model_tp, type="simple")
model_tp
conf_mat_tp = predict(model_tp, newdata = test, type = "response")
conf_mat_info_tp <- confusionMatrix(conf_mat,test$Attrition)
conf_mat_info_tp
conf_mat_info_dt
plot(model_tp, type="simple")
runApp('main.R')
runApp('main.R')
#ROC
predict = predict(model_dt, newdata = test, type = "prob")[,1]
par(pty="s")
roc(response = test$Attrition, predictor = predict,plot=TRUE, legacy.axes = TRUE, percent = TRUE, xlab= "False Positive Perc.", ylab= "True Positive Perc.",
col="#377EB8",lwd=4, print.auc=TRUE)
#ROC_rf
predict = predict(model_rf, newdata = test, type = "prob")[,1]
par(pty="s")
roc(response = test$Attrition, predictor = predict,plot=TRUE, legacy.axes = TRUE, percent = TRUE, xlab= "False Positive Perc.", ylab= "True Positive Perc.",
col="#377EB8",lwd=4, print.auc=TRUE)
#ROC_rf
predict = predict(model_rf, newdata = test, type = "prob")[,1]
#ROC_rf
predict = predict(model_rf, newdata = test, type = "prob")#[,1]
View(predict)
#ROC_rf
predict = predict(model_rf, newdata = test, type = "prob")[,1]
par(pty="s")
roc(response = test$Attrition, predictor = predict,plot=TRUE, legacy.axes = TRUE, percent = TRUE, xlab= "False Positive Perc.", ylab= "True Positive Perc.",
col="#377EB8",lwd=4, print.auc=TRUE)
#ROC
predict = predict(model_dt, newdata = test, type = "prob")[,1]
par(pty="s")
roc(response = test$Attrition, predictor = predict,plot=TRUE, legacy.axes = TRUE, percent = TRUE, xlab= "False Positive Perc.", ylab= "True Positive Perc.",
col="#377EB8",lwd=4, print.auc=TRUE)
#ROC
predict_dt = predict(model_dt, newdata = test, type = "prob")[,1]
par(pty="s")
roc_dt <-  roc(response = test$Attrition, predictor = predict_dt,plot=TRUE, legacy.axes = TRUE, percent = TRUE, xlab= "False Positive Perc.", ylab= "True Positive Perc.",
col="#377EB8",lwd=4, print.auc=TRUE)
roc_dt
roc_dt
#ROC
predict_dt = predict(model_dt, newdata = test, type = "prob")[,1]
par(pty="s")
runApp('main.R')
roc(response = test$Attrition, predictor = predict_rf,plot=TRUE, legacy.axes = TRUE, percent = TRUE, xlab= "False Positive Perc.", ylab= "True Positive Perc.",
col="#377EB8",lwd=4, print.auc=TRUE)
roc_dt <-  roc(response = test$Attrition, predictor = predict_dt,plot=TRUE, legacy.axes = TRUE, percent = TRUE, xlab= "False Positive Perc.", ylab= "True Positive Perc.",
col="#377EB8",lwd=4, print.auc=TRUE)
roc(response = test$Attrition, predictor = predict_rf,plot=TRUE, legacy.axes = TRUE, percent = TRUE, xlab= "False Positive Perc.", ylab= "True Positive Perc.",
col="#377EB8",lwd=4, print.auc=TRUE)
#ROC_rf
predict_rf = predict(model_rf, newdata = test, type = "prob")[,1]
par(pty="s")
roc(response = test$Attrition, predictor = predict_rf,plot=TRUE, legacy.axes = TRUE, percent = TRUE, xlab= "False Positive Perc.", ylab= "True Positive Perc.",
col="#377EB8",lwd=4, print.auc=TRUE)
runApp('main.R')
conf_mat_dt = predict(model_dt, newdata = test, type = "class")
conf_mat_info_dt <- confusionMatrix(conf_mat_dt ,test$Attrition)
conf_mat_info_dt
conf_mat_info_dt
#model randomForest
model_rf <- randomForest::randomForest(Attrition ~ .,data = train)
model_rf <- randomForest::randomForest(Attrition ~ .,data = train,ntree=100, mtry=2)
model_rf
conf_mat_rf = predict(model_rf, newdata = test, type = "class")
conf_mat_info_rf <- confusionMatrix(conf_mat_rf ,test$Attrition)
conf_mat_info_rf
model_dt
model_rf
runApp('main.R')
conf_mat_info_rf
runApp('main.R')
model_dt
#model randomForest
model_rf <- randomForest::randomForest(Attrition ~ .,data = train)
model_rf
model_rf <- randomForest::randomForest(Attrition ~ .,data = train,ntree=100, mtry=2)
model_rf
runApp('main.R')
runApp('main.R')
